---
title: "Nonparametric Tests"
subtitle: "One and Two Sample Tests"
author: "Ranadeep Daw"
date: "`r Sys.Date()`"
output:
  slidy_presentation:
    theme: "flatly"
    center: true
    widescreen: true
    self_contained: true
    width: 1600
    height: 900
    df_print: kable
    reveal_options:
      slideNumber: true
      previewLinks: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F)
```

## Recap

1. Calculation of descriptive statistics, e.g., mean, median, quantiles, IQR.
2. Estimation under normality assumption.
3. Confidence intervals and hypothesis testing.
  - One sample $t$ test: Two-sided and one-sided
  - Two sample $t$ test: Two-sided and one-sided
    * Paired sample
    * Independent sample
      - Equal Variance
      - Unequal Variance
      
      
## Recap: $\texttt{R}$ Syntaxes

1. <span style = "color:blue;">Descriptive: </span> $\texttt{mean}(...)$, $\texttt{median}(...)$, $\texttt{quantile}(...)$, $\texttt{boxplot}(...)$.
2. <span style = "color:blue;">T-test and CI:</span> $$\texttt{t.test(..., alternate=..., mu=..., conf.level = ...)}$$
3. <span style = "color:blue;">Two sample T-test and CI:</span> $$\texttt{t.test(vec1, vec2, alternate=..., mu=..., conf.level = ...)}$$
  * <span style = "color:limegreen;">For paired sample, </span> add **$\texttt{paired=TRUE}$**.
  * <span style = "color:limegreen;">For independent sample, </span> **$\texttt{paired=FALSE}$** (by default).
    - <span style = "color:purple;">Equal variance:</span> add **$\texttt{vùöäùöõ.ùöéùööùöûùöäùöï = FALSE}$**.
    - <span style = "color:purple;">Unequal variance:</span> **$\texttt{ùöüùöäùöõ.ùöéùööùöûùöäùöï = TRUE}$** (by default).


## Practice^[Examples taken from Biostatistical Analysis]: Q1

Test that male and female turtles have the same mean serum cholesterol concentrations. Take $\alpha = 0.05$.

Male: 220.1 , 218.6 , 229.6 , 228.8 , 222.0 , 224.1 , 226.5
Female: 223.4, 221.5, 230.2, 224.3, 223.8, 230.8.

* $H_0$: $\mu_1 - \mu_2 = 0$, $H_A$: $\mu_1 - \mu_2 \neq 0$ 
* Two sided test, two sample.

## Cont.

```{r}
cholesterol = c(220.1 , 218.6 , 229.6 , 228.8 , 222.0 , 224.1 , 226.5,
                223.4, 221.5, 230.2, 224.3, 223.8, 230.8)
gender = c(rep("1.Male", 7), rep("2.Female", 6))
t.test(cholesterol ~ gender, conf.level = 1-0.05,
        mu = 0, alternative = "two.sided", var.equal=TRUE)
```

* $p$ value > $\alpha$. Hence reject $H_0$.



## Practice 2

From the following wing-legnth data (in mm), test if the population mean for birds from south is $\geq$ 5mm than the population mean for birds from north. Take $\alpha = 0.05$.

South birds: 116, 117, 121, 114, 116, 118, 123


North birds: 120, 113, 125, 118, 116, 114, 119, 120

* $H_0$: $\mu_S$ (Mean of south) - $\mu_N$ (north) $\leq 5$
* $H_A$: $\mu_S$ (Mean of south) - $\mu_N$ (north)  > 5

## Cont.


```{r}
wing_lengths = c( 116, 117, 121, 114, 116, 118, 123,
                  120, 113, 125, 118, 116, 114, 119, 120)
bird_type = c(rep("1.S", 8), rep("2.N", 7))
t.test(wing_lengths ~ bird_type, conf.level= 1 - 0.05,
       alternative = "greater", mu=5)
```



## Normality Assumptions

* Recall, we assumed that our sample is from a population that follows a normal distribution $\mathbb{N}( \mu, \sigma^2)$.

  - Symmetric around it's mean, population mean = population median = $\mu$.
  - High probabilities near the center, lower probabilities near the tails.
  
* What if our assumptions are wrong?

## Probability Distribution

```{r echo=F}
# Define mean and standard deviation
mu <- 0
sigma <- 1

# Generate a sequence of x values
x <- seq(mu - 4 * sigma, mu + 4 * sigma, length = 1000)

# Calculate the normal density
y <- dnorm(x, mean = mu, sd = sigma)

# Plot the normal distribution curve
plot(x, y, type = "l", lwd = 2, col = "blue", xaxt = "na",
     xlab = "x",
     ylab = "Density",
     main = "Normal Probabilities")

# Shade regions and add vertical lines
regions <- list(
  list(from = mu - 4*sigma, to = mu - 3 * sigma, col = "lightblue", label = "0.0015"),
  list(from = mu - 3 * sigma, to = mu - 2 * sigma, col = "lightblue", label = "0.02"),
  list(from = mu - 2 * sigma, to = mu - sigma, col = "lightgreen", label = "0.14"),
  list(from = mu - sigma, to = mu, col = "lightpink", label = "0.34"),
  list(from = mu + sigma, to = mu, col = "lightpink", label = "0.34"),
  list(from = mu + 2 * sigma, to = mu + sigma, col = "lightgreen", label = "0.14"),
  list(from = mu + 3 * sigma, to = mu + 2 * sigma, col = "lightblue", label = "0.02"),
  list(from = mu + 4 * sigma, to = mu + 3 * sigma, col = "lightblue", label = "0.0015")
)
  


# Add shaded regions and labels
for (region in regions) {
  rect(region$from, 0, region$to, dnorm(region$from), border = NA)
  text(mean(c(region$from, region$to)), dnorm(mu) * 0.1, labels = region$label, col = "black")
}

# Add vertical lines
abline(v = mu, lty = 2)
abline(v = c(mu - sigma, mu + sigma), lty = 2)
abline(v = c(mu - 2 * sigma, mu + 2 * sigma), lty = 2)
abline(v = c(mu - 3 * sigma, mu + 3 * sigma), lty = 2)

# Add axis labels using Greek letters
axis(1, at = c(mu - 4 * sigma, mu - 3 * sigma, mu - 2 * sigma, mu - sigma, mu, mu + sigma, mu + 2 * sigma, mu + 3 * sigma, mu + 4 * sigma),
     labels = expression(-infinity, mu - 3 * sigma, mu - 2 * sigma, mu - sigma, mu, mu + sigma, mu + 2 * sigma, mu + 3 * sigma, infinity)
     )


```



## Departure from Normality Assumptions

\newcommand{\X}{\mathrm{X}}



- **Departure from Normality**: Occurs when the sample suggests that the population does not follow a normal distribution.
- **Consequences**:
  - Can affect the validity of statistical tests (e.g., t-tests).
  - May lead to incorrect conclusions.
- **Common Causes of Departure:**
  - **Skewness**: Asymmetry in the distribution.
  - **Kurtosis**: Peakedness or flatness compared to a normal distribution.



## Example

```{r echo=F, out.width=700}
data = rnorm(5000, 0, 1)
par(mfrow = c(1, 2))
# Example R code to plot histogram
hist(data, main = "Example of Normality", xlab = "x", ylab = "Count", col = "skyblue", border = "black", breaks = 100)
hist(data[data > 0], main = "Departure from Normality", xlab = "x", ylab = "Count", col = "skyblue", border = "black", breaks = 100)
```



## Non parametric Methods


- **Definition**: Statistical methods that do not assume a specific distribution for the population.
- **Difference from Parametric Methods**:
  - **Parametric**: 
    * Assumes data follows a known distribution (e.g., normal, $t$, etc.).
    * Estimates the parameter of the distribution (e.g., $\mu, \sigma^2$ for normal).
    * We estimate the population parameter first, then estimate other unknown quantities (e.g., median in normal).
  - **Nonparametric**: 
    * Makes no such assumptions about the underlying data distribution.
    * <span style="color:green">It still has parameters to be estimated.</span>
    * Sample estimates are usually good candidates for equivalent population parameters. 
    

## Examples of Usage of Nonparametric Methods

- **Small Sample Sizes**: When the sample size is too small to reliably estimate parameters.
- **Non-Normal Data**: When data significantly departs from normality.
- **Ordinal Data**: When dealing with ordinal data or ranks rather than interval data.




## Example: 

* **Q: What are the estimates of mean, variance, and median for $\texttt{mpg}$ from $\texttt{mtcars}$ data i) Under normality? ii) Under nonparametric method?**


```{r}
data("mtcars")
MPG = mtcars$mpg
mean(MPG)
var(MPG)
median(MPG)
```

## Cont.

1. **Under normality,**

  i. Estimate of mean = 20.09062
  ii. Estimate of median = 20.09062
  iii. Estimate of variance = 36.3241

2. **In nonparametric method,**

  i. Estimate of mean = 20.09062
  ii. Estimate of median = 19.2
  iii. Estimate of variance = 36.3241

## Necessary: Binomial Distribution

* Recall the coin toss example:
  1. I tossed a coin $n$ times and got $x$ many heads.
  2. Each event (toss) has two possible outcomes (here H/T).
  2. Different events (tosses) are independent.
  
* Define X = Number of heads out of $n$ tosses.
* We say $X \sim$ Binomial(n,p).
* If I toss a coin $n$ times, number of heads can be $0, 1, \ldots, n$.
* Probaility distribution: $\mathbb{P}(X = x)$ = $n \choose x$ $p^x (1-p)^{n-x}$

  - Note: $n \choose x$ = $\frac{n!}{x! (n-x)!}$

## Binomial probabilities

```{r echo=F}
n = 50
x = 0:n
plot(x, dbinom(x, n, 0.5, log=F), main = "Probabilities for p=0.5", xaxt="na", yaxt = "na", col="red", cex = 0.5, ylab = "Probability", xlab = "x")
```




## Binomial probabilities

```{r echo=F}
n = 50
x = 0:n
plot(x, dbinom(x, n, 0.2, log=F), main = "Probabilities for p=0.2", xaxt="na", yaxt = "na", col="red", cex = 0.5, ylab = "Probability", xlab = "x")
```



## Binomial probabilities

```{r echo=F}
n = 50
x = 0:n
plot(x, dbinom(x, n, 0.8, log=F), main = "Probabilities for p=0.8", xaxt="na", yaxt = "na", col="red", cex = 0.5, ylab = "Probability", xlab = "x")
```

## Parametric and Non-parametric Tests


| **Test Type**          | **Parametric Test**          | **Nonparametric Test**                     |
|------------------------|------------------------------|--------------------------------------------|
| **1-sample test**      | One-sample t-test         | Sign test                 |
| **2-sample test (paired)** | Paired t-test              | Wilcoxon signed-rank test (for paired samples) |
| **2-sample test (unpaired)** | Two-sample t-test          | Mann-Whitney U test (Wilcoxon rank-sum test) |




## Sign Test

- **Sign Test**: A nonparametric test used to evaluate if the **<span style=  "color:purple;">median</span>** of a single sample differs from a hypothesized value.
- **Purpose**: Test if the population median of a sample $\X = \{x_1, \ldots, x_n \}$ is $\mu_0$.
- **Hypotheses**: $H_0$: M (median) = $\mu_0$; $H_1:$ M $\neq, \leq, or \geq$ $\mu_0$.


## Procedure

i. Assign  a "plus"/success (+) to numbers $\geq$ $\mu_0$, a "minus"/failure otherwise.
    
  * If $x_i > \mu_0$, it's a + or success.
  * If $x_i < \mu_0$, it's a - or failure.
  
ii. Test statistic: T =  Total number of success
iii. Under $H_0$, the number of **+** and **-** should be roughly equal, following a **binomial distribution** with probability $p = 0.5$. (Recall the head/tail count from coin toss example).
iv. $p$ value = Probability that a Binomial(n, 0.5) variable is at least as extreme as T.
v. Reject $H_0$ if $p$ value < $\alpha$.


## Example: `mtcars` Dataset

**Let's test if the median MPG from the $\texttt{mtcars}$ data is 18 or not.**
 
- $H_0$: M (Median mpg) = 18 vs $H_A$: M $\neq$ 18. Test at $\alpha = 0.05$.
- Data: <center> 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8, 16.4, 17.3, 15.2, 10.4, 10.4, 14.7, 32.4, 30.4, 33.9, 21.5, 15.5, 15.2, 13.3, 19.2, 27.3, 26.0, 30.4, 15.8, 19.7, 15.0, 21.4 </center>
- Plus signs (19): <center><span style="color:blue"> 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 24.4, 22.8, 19.2, 32.4, 30.4, 33.9, 21.5, 19.2, 27.3, 26.0, 30.4, 19.7, 21.4</span></center>
- Minus signs (13): <center><span style="color:green"> 14.3, 17.8, 16.4, 17.3, 15.2, 10.4, 10.4, 14.7, 15.5, 15.2, 13.3, 15.8, 15.0
</span> </center>
- Remaining part of the test will use the $\texttt{binom.test}$ function in $\texttt{R}$. 


## $\texttt{R}$ syntax

```{r eval=F}
binom.test(<positives_count>, <total_count>, alternative = <alternative>, conf.level=<1-alpha>)
```


**Example**

```{r}
binom.test(19, 32, alternative = "two.sided", conf.level = 1-0.05)
```

## (Contd.)


```{r}
data(mtcars)
hypothised_median = 18
MPG = mtcars$mpg
positives_count   = sum(MPG > hypothised_median)
negatives_count   = sum(MPG < hypothised_median)
binom.test(positives_count, positives_count + negatives_count, 
                    alternative = "two.sided", conf.level = 1-0.05)
```







## Decision

* p-value > $\alpha$, hence can not reject $H_0$.
* Alternatively, confidence interval for $p$ contains $0.5$. Hence can not reject $H_0$.






## Mann-Whitney Test / Wilcoxon Rank-Sum Test

* Equivalent of two sample independent $t$ test.
  - Group 1: $\X_1: \{x_{11}, x_{12}, \cdots, x_{1m} \}$. 
  - Group 2: $\X_2: \{x_{21}, x_{22}, \cdots, x_{2n} \}$.
  - $H_0$: $M_1$ (Median of sample 1) = $M_2$ (Median of sample 2)
  - $H_A$: $M_1$ $\neq, \leq, or \geq$ $M_2$.
  
## Procedure

1. Combine both the samples together.
2. Rank them together. Smallest = Rank 1, largest = Rank (m + n).
3. S = Sum of ranks of sample 1.
4. For large samples, under $H_0$, S follows normal distirbution with mean $\mu_S = \frac{m(m+n+1)}{2}$,  variance $\sigma^2_S = \frac{mn(m+n+1)}{12}$. 
5. Test statistic 2: W = $\frac{S - \mu_S}{\sigma_S}$.
6. Reject if:
  
  - $|W| > z_{\alpha/2}$ if $H_A: M_1 \neq M_2$
  - $W \geq z_{\alpha}$ if $H_A: M_1 \geq M_2$
  - $W \leq z_{\alpha}$ if $H_A: M_1 \leq M_2$



## Example: Method of Ranking

* Group 1: $\{15, 20, 22, 21, 18 \}$.
* Group 2: $\{9, 16, 25, 12, 10, 11, 17, 8 \}$.
* **Step 1 : Combine together.**
  <center> <span style = "color:red"> 15, 20, 22, 21, 18, </span> <span style = "color:blue">9, 16, 25, 12, 10, 11, 17, 8</span>
* **Step 2: Rank them** <span style = "color:red"> 
6, 10, 12, 11, 9, </span> <span style = "color:blue">2, 7, 13, 5, 3, 4, 8, 1</span>
* Sum of rank of sample 1: S = 48.





## Example from Last class

This table shows an example of heights of plants under two different fertilizers. Test if the new fertilizer is working better, i.e., average height under the new fertilizer is more than the earlier one. <br><br>
<center> Old fertilizer: **<span style = "color:red">48.2, 54.6, 58.3, 47.8, 51.4, 52.0, 55.2, 49.1, 49.9, 52.6</span>**</center>
<center> New fertilizer: **<span style = "color:red">52.3, 57.4, 55.6, 53.2, 61.3, 58.0, 59.8, 54.8</span>** </center>


## Cont.

* $M_1$ = Median height under old fertilizer 
* $M_2$ = Median height under new.
* $H_0$: $M_1 \geq M_2$.
* $H_A$: $M_1$ < $M_2$.
* Independent sample, one-sided test.


## $\texttt{R}$ syntax

Syntax:
```{r eval=F}
wilcox.test(<values> ~ <group>, conf.level = 1- <alpha>, 
            mu = 0, alternative="less", exact=FALSE)
```

Example:
```{r}
height = c(48.2, 54.6, 58.3, 47.8, 51.4, 52.0, 55.2, 49.1, 49.9, 52.6,
           52.3, 57.4, 55.6, 53.2, 61.3, 58.0, 59.8, 54.8)
fertilizer = c(rep("1.Old", 10), rep("2.New", 8))
wilcox.test(height ~ fertilizer, conf.level = 1-0.05, mu = 0,
            alternative="less", exact=FALSE)
```



## Wilcoxon Signed-Rank Test 


* Equivalent of two sample paired $t$ test.
  -   |           | Subject 1 | Subject 2 | $\ldots$ | Subject n | 
|-----------|-----------|-----------|-----------|-----------|
| **Variable 1** |     $x_{11}$    |     $x_{12}$    |     $\ldots$    |    $x_{1n}$  |
| **Variable 2** |     $x_{21}$    |     $x_{22}$    |     $\ldots$    |     $x_{2n}$    |   

  - $H_0$: $M_1$ (Median of variable 1) = $M_2$ (Median of variable 2)
  - $H_A$: $M_1$ $\neq, \leq, or \geq$ $M_2$.


## Procedure

1. Form the differences and signs:

|           | Subject 1 | Subject 2 | $\ldots$ | Subject n | 
|   -----------|   -----------|   -----------|   -----------|   -----------|
| **Variable 1** |     $x_{11}$                     |     $x_{12}$                   |     $\ldots$    |    $x_{1n}$  |
| **Variable 2** |     $x_{21}$                     |     $x_{22}$                   |     $\ldots$    |     $x_{2n}$    | 
| **Difference** |     $d_1 = (x_{11} - x_{21}$)    |     $d_2 = (x_{12} - x_{22})$    |     $\ldots$    |     $d_n = (x_{1n} - x_{2n})$    | 
| **Signs** |     $S_1 = +1$ if $d_1 > 0$, -1 ow.    |     $S_2 = +1$ if $d_2 > 0$, -1 ow.    |     $\ldots$    |     $S_n = +1$ if $d_n > 0$, -1 ow.    | 

2. Rank the absolute differences $|d_i|$ in increasing order (lowest = 1 to highest = (m+n)).

## Procedure (cont.)

3. $T = S_1 d_1 + S_2d_2 + \ldots + S_nd_n$.
4. For large sample size, under $H_0$: $\mathbb{E}(T) = 0$;  var$(T) = \sigma_T^2 = \frac{n(n+1)(2n+1)}{6}$.
5. Test statistic: Z = $\frac{T - 0}{\sigma_T}$.
6. Reject if:
  
  - $|Z| > z_{\alpha/2}$ if $H_A: M_1 \neq M_2$
  - $Z \geq z_{\alpha}$ if $H_A: M_1 \geq M_2$
  - $Z \leq z_{\alpha}$ if $H_A: M_1 \leq M_2$



## Example from last class: Deer leg lengths


* I want to test if the median hindleg length and foreleg length of deers are the same from the following sample:

```{r}
Foreleg_Length = c(142, 140, 144, 144, 142, 146, 149, 150, 142, 148)
Hindleg_Length = c(138, 136, 147, 139, 143, 141, 143, 145, 136, 146)
```


* Note: paired data, two-sided test.
* $H_0$: $M_1 = M_2$ vs $H_A$: $M_1 \neq M_2$.



## Cont.

*Step 1:* Calculate the differences and signs.

```{r}
diffs = Foreleg_Length - Hindleg_Length
signs = sign(diffs) # sign function calculates sign
diffs
signs
```


*Step 2:* Calculate the signed-rank sum
```{r}
T = sum(diffs * signs)
T
```

Remaining code will use the $\texttt{wilcox.test}$ function.


## $\texttt{R}$ Syntax

Syntax:
```{r eval=F}
wilcox.test(<var1>, <var2>, alternative = <"greater", "less", or "two.sided">,
            mu = 0, paired = TRUE, exact = FALSE, conf.level =  1 - <alpha>)
```

Example:
```{r}
wilcox.test(Foreleg_Length, Hindleg_Length, alternative = "two.sided",
            mu = 0, paired = TRUE, exact = FALSE, conf.level = 0.95)
```

Reject $H_0$ since $p$-value <$\alpha$.



